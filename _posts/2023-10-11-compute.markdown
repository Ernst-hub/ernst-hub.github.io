---
layout: post
comments: true
title:  "Notes on compute"
excerpt: "Notes on compute"
date:   2023-10-11 22:00:00
category: "Compute"
mathjax: true
---

> “Civilization advances by extending the number of important operations which we can perform without thinking about them.”
>
> Alfred North Whitehead, AN Introduction to Mathematics, 1911


<img src="/assets/compute/image-20230729211418372.png" alt="image-20230729211418372" style="zoom:22%;" />

- [Recent trends](#recent-trends)
- [Chapter 1](#chapter-1)
	- [Great ideas in computer architecture](#great-ideas-in-computer-architecture)
	- [Basic functions of the underlying hardware:](#basic-functions-of-the-underlying-hardware)
		- [The processor:](#the-processor)
		- [Memory:](#memory)
		- [Language](#language)
	- [Big pictures](#big-pictures)
	- [Safe place for data (how it is stored when we shut the pc down)](#safe-place-for-data-how-it-is-stored-when-we-shut-the-pc-down)
	- [Tech for building processors](#tech-for-building-processors)
		- [How a chip is made:](#how-a-chip-is-made)
	- [Performance](#performance)


## Recent trends

We have switched from one core to mutlicore processing

why?

A good argument is the fact that [Moore's law](https://en.wikipedia.org/wiki/Moore%27s_law) and [Dennard scaling](https://www.google.com/search?rlz=1C5CHFA_enDK1049DK1049&sxsrf=AB5stBgRF1Yw-KiKjezY4zL_MeSXJGCO2A:1690653894324&q=why+did+dennard+scaling+end&tbm=vid&source=lnms&sa=X&ved=2ahUKEwiFh7zGwLSAAxVr87sIHYq9DQsQ0pQJegQICxAB&biw=1382&bih=941&dpr=2.5#fpstate=ive&vld=cid:c651395a,vid:dK66mV6RU5Q) has shown to slow in some cases. Therefore, to increase compute, we increase power with diminishing returns to increase processing speeds. This is done by combining cores.

[Amsdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law) says that: "the overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used." 

A special type of architecture (aside from the general purpose CPU) has gained increasing popularity. It is the *Domain specific architecture* (DSA), these are processors that are used and optimized for a specific use-case/domain.

Cloud and SaaS has made it lucrative for firms to invest in their own DSA's following open-source instruction sets such as RISC-V. 



## Chapter 1

Understanding program performance



| **Hardware / software component**                    | **How component affects performance**                            | **Where this topic is covered** |
| ------------------------------------------------ | ------------------------------------------------------------ | --------------------------- |
| Algorithm                                        | Determines the number of source-level statements and the number of I/O operations executed | Other books                 |
| Programming language, compiler, and architecture | Determines the number of computer instructions for each source-level statement | C2,3                        |
| Processor and memory system                      | Determines how fast instructions can be executed             | C4,5,6                      |
| I/O system (hardware and operating system)       | determines for fast I/O ops may be executed                  | C4,5,6                      |



### Great ideas in computer architecture

1. Use abstraction to simplify design
2. Make common use cases fast rather than edge cases
3. Parallelism to increase performance (do computations in parallel)
4. Performance via pipelining (lining up operations efficiently, a common parallellism pattern)
5. Performance via prediction: it can be faster to guess and start working rather than wait for certainty
6. Hierarchy of memories: fast, small and most expensive memory per bit at the top of the hierarchy and the slowest, largest and cheapest bit at the bottom
7. Dependability via redundancy: make systems dependable by including redundant components to avoid single points of failure. Redundant components must be designed to replace *and* to detect when a failure occurs



### Basic functions of the underlying hardware:

Inputting data, outputting data, processing data, and storing data.

The five components that allow the computer to perform these tasks:

1. Input: feeds the computer with information
	1. Could be a microphone
2. Output: feeds the user the processed input
	1. Could be a speaker
3. Memory: where the programs are kept when they are running; it also contains the data needed by running programs.
	1. DRAM is found in the iPhone, DRAM (dynamic random-access memory) are used together to contain instructions and data of a program. In contrast to sequential-access memory, such as magnetic tapes, the *RAM* portion of the term DRAM means that memory accesses take basically the same amount of time no matter what portion of memory is read. (we will go back to memory)
4. Datapath: Performs arithmetic ops
5. Control: tells the datapath, memory and I/O devices to do according with the instructions provided.

<img src="/assets/compute/image-20230729214456850.png" alt="/assets/compute/image-20230729214456850.png" style="zoom:22%;" />

#### The processor:

The processor logically comprises two main components: datapath and control, the respective brawn and brain of the processor. 

1. The **datapath** performs the arithmetic operations, and 
2. **control** tells the datapath, memory, and I/O devices what to do according to the wishes of the instructions of the program.

#### Memory:

`DRAM`: dynamic random-access memory - Memory built as an integrated circuit; it provides random access to any location. Access times are 50 nanoseconds and cost per gigabyte in 2012 was USD5 to USD10.

`Cache memory`: small and fast memory acting as a DRAM buffer (a safe place for hiding things). Caches are built using SRAM. 

`SRAM`: Static random access memory - faster but less dense and hence more expensive than DRAM (C5)



#### Language

`The instruction set architecture` also called `the architecture` is the lowest level programming language that provides the hardware with instructions. The instruction set architecture includes anything programmers need to know to make a binary machine language program work correctly, including instructions, I/O devices, and so on. 

Typically, the operating system will encapsulate the details of doing I/O, allocating memory, and other low-level system functions so that application programmers do not need to worry about such details. The combination of the basic instruction set and the operating system interface provided for application programmers is called the `application binary interface (ABI)`.

When the hardware obeys the architecture abstractions provided by an instruction set architecture, we talk of an `implementation`.

### Big pictures

- The five components of a computer: I/O, store, process, and control

- Both hardware and software consist of hierarchical layers using abstraction, with each lower layer hiding details from the level above. One key interface between the levels of abstraction is the *instruction set architecture* - the interface between the hardware and low-level software. This abstract interface enables many *implementations* of varying cost and performance to run identical software.
- 

### Safe place for data (how it is stored when we shut the pc down)

Memory can be divided into:

`volatile memory` storage such as DRAM that retains memory only when receiving power

- also coined primary memory

`non-volatile memory` storage that retains memory even in the absence of a power source (a DVD for example)

- also coined secondary memory
- "flash memory" is a semiconductor memory used in most mobile devices.
- It is slower and cheaper than DRAM 
- disks are also secondary memory, they are less power efficient than flash memory



### Tech for building processors

`transistor`: an on/off switch controlled by electricity. The integrated circuit (IC) combines hundreds/thousands/millions of transistors into a single chip depending on its purpose. In an M1 Max, we have 57 billion transistors.

`Silicon` does not conduct electricity well, it is therefore a `semiconductor`. With a special chemical process, we can add materials to the silicon, allowing for tiny areas to transform into one of three devices:

- excellent conductor of electricity (by adding copper or aluminium wire (microscopic))
- excellent insulators from electricity (like plastic sheathing)
- areas to conduct or insulate under specific conditions (switch on/off) - this is transistors.

A very large  `integrated circuit` is a conglomerate of these three features.

#### How a chip is made:

<img src="/assets/compute/image-20230802224849099.png" alt="/assets/compute/chips" style="zoom:22%;" />

During the process of creating the patterned wafers, it is almost impossible to secure no defects. For that reason, to cope with this circumstance, we place many independent components on a single wafer. the patterned wafer is then diced into these components called dies (also known as `chips`). Dicing enables you to discard only those dies that were unlucky enough to contain the flaws, rather than the whole wafer.


<img src="/assets/compute/image-20230802225922168.png" alt="/assets/compute/chips2" style="zoom:22%;" />

### Performance

`response time` or `execution time`: the total time required by a computer to complete a task.

`throughput` or `bandwidth`: the number of tasks completed per unit time.

For a computer \\(X\\), we say that its performance is as follows:

\\(\operatorname{Performance}_X = \frac{1}{\operatorname{Execution time}_X}\\)

To compare computers \\(X\\) and \\(Y\\):

\\(\frac{\operatorname{Performance}_X}{\operatorname{Performance}_Y} = \frac{\operatorname{Execution time}_Y}{\operatorname{Execution time}_X} = n\\), i.e., \\(X\\) is \\(n\\) times faster than \\(Y\\)

*Measuring performance*

Time is the measure of computer performance: the computer that performs the same amount of work in the least time is the fastest. The most straightforward definition of time is called *wall clock time*, *response time*, or *elapsed time*. These terms mean the total time to complete a task, including disk accesses, memory accesses, *input/output* (I/O) activities, operating system overhead—everything. **Caveat**: we could be running other programs in the background effectively disturbing comparisons between computers.

`CPU (execution) time` is the time the CPU spends computing a task, and does not include time spent waiting for I/O or running other programs. This is a way to deal with the caveat.

`CPU time` can be further divided into the CPU time spent in ONE program, called `user CPU time`, and the CPU time spent in the operating system performing tasks on behalf of the program, called `system CPU time`.

Differentiating between system and user CPU time is difficult to do accurately, because it is often hard to assign responsibility for operating system activities to one user program rather than another and because of the functionality differences between operating systems.



`clock cycle`: the time for one clock period (usually of the processor clock which runs at a constant rate). A clock rate is the inverse of a clock cycle.

CPU execution time for a program = CPU clock cycles for a program times Clock cycle time

$$
\begin{align}
\text{CPU execution time for a program} =  \\\text{CPU clock cycles for a program} \times \text{Clock cycle time}=   \\
\frac{\text{CPU clock cycles for a program} }{\text{Clock rate} }
\end{align}
$$

because CPU cycle time and Clock rate are in an inverse relationship.



CPU clock cycles can be understood as the number instructions executed multiplied by the average time per instruction:

$$
\begin{align}
\text{CPU clock cycles} = & \\ \text{Instructions for a program}  \times  \text{Average clock cycles per instruction}
\end{align}
$$

`clock cycles per instruction (CPI)`: average number of clock cycles each instruction takes to execute. \\(\text{CPI} = \frac{\text{CPU clock cycles} }{\text{Instruction count} }\\).

**The classic equations:**

This lead us to CPU time in terms of instruction count (# of instructions executed by a program): 

$$
\begin{align}
\text{CPU time} & = & \text{Instruction count} \times \text{CPI} \times \text{Clock cycle time} \\ 
& = & \text{Instruction count} \times \text{CPI} \times \text{Clock rate}^{-1}
\end{align}
$$

These formulas are particularly useful because they separate the three key factors that affect performance. We can use these formulas to compare two different implementations or to evaluate a design alternative if we know its impact on these three parameters.


## Chapter 2: instructions, language of the computer

RISC-V
- An instruction language needs to be simple and practical. 
- RISC-V requires every instruction to the computer to take three operands.

For example: 
```python
f = (g + h) - (i + j)
```

in RISC-V: 

```
add v, g, h // store sum as temp var
add w, i, j // store sum as temp var
sub f, v, w // calc f, by sub
```

**Registers and memory**

In RISC-V math operations such as ``add`` ``sub`` are done in registers. 
There are 32bit registers in the architecture. Why? Smaller is faster, increasing the number of registers may increase clock cycle time. Double why? becayse the electronic signals may have to travel farther, ultimately resulting in slower computation. 

Each register is represented by an x followed by the number: ``x19`` for instance.

But we have billions of data points? How do we do operations then? 

Just thinking about the CPU, what we do is provide *data transfer instructions*, that transfer data between memory and registers.
When we copy data from memory to a register, we `load`

``g = h + A[8]`` : equivalent to first, load A[8] to some register. Assume the A-array begins at register x22, then we have the following instruction:
``lw x9, 32(x22) // load word, from x22`` (beginning of the array) offset by (4*8=32), because each word is represented by four bytes, and each memory address stats at the fist byte. Hence, the memory address of the 8th item in the array is found at the 32rd byte... 

Complementary to loadm we have store word (``sw``) which copies data from a registry and stores it in memory.


*Good quote on the difference between registers and memory*:
> Many programs have more variables than computers have registers. Consequently,
the compiler tries to keep the most frequently used variables in registers and places
the rest in memory, using loads and stores to move variables between registers and
memory. The process of putting less frequently used variables (or those needed
later) into memory is called spilling registers. [...] A RISC-V arithmetic
instruction can read two registers, operate on them, and write the result. A RISC-V
data transfer instruction only reads one operand or writes one operand, without
operating on it. Thus, registers take less time to access and have higher throughput than memory,
making data in registers both considerably faster to access and simpler to use.
Accessing registers also uses much less energy than accessing memory. To achieve
the highest performance and conserve energy, an instruction set architecture must
have enough registers, and compilers must use registers efficiently.  *page 78 in the [book](https://shop.elsevier.com/books/computer-organization-and-design-risc-v-edition/patterson/978-0-12-820331-6)

Below is a depiction of a 32bit wide register, containing the binary representation of the number: 11.
<img src="/assets/compute/registers.png" alt="/assets/compute/registers" style="zoom:22%;" />

As you can see, registers are filled right to left. In case *overflow* occurs, i.e. the resulting numbers are larger than what can be represented by the register, it is up to the OS / software to decide what to do.


